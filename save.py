# -*- coding: utf-8 -*-
"""Visualize modulation reconstructions.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/github/deepmind/functa/blob/main/modulation_visualization_colab.ipynb

# Download and run a LatentModulatedSIREN model pre-trained on CelebA-HQ-64
This demo shows how to load the pretrained weights from a LatentModulatedSIREN model, from the paper [From data to functa: Your data point is a function and you can treat it like one]() (Dupont, Kim, Eslami, Rezende, Rosenbaum. 2022). It uses code from the official [JAX](https://github.com/google/jax) + [Haiku](https://github.com/deepmind/dm-haiku) implementation.


It's recommended to use `Runtime->Change Runtime Type` to pick a GPU for speed.
"""

# Copyright 2022 DeepMind Technologies Limited. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
# ==============================================================================
# !pip install chex
# !pip install dm-haiku
# !pip install dill
# !pip install matplotlib
# !pip install optax
# !git clone https://github.com/deepmind/functa/

#这个代码用来把生成的modulation以及预训练的参数合并生成图像数据并将其保存下来的，具体可视化图片在visualize.py这个代码中

import dill
import haiku as hk
import jax
import jax.numpy as jnp
import matplotlib.pyplot as plt
import numpy as np
import optax
import os
from PIL import Image
from  functa import embed_fnn
import function_reps, pytree_conversions



import numpy as np
import os
from PIL import Image

#这段代码实现了将保存的图片数据进行可视化生成图片并保存下来。
def visualize_and_save_raw_data(input_path, output_dir):
    """加载原始数据并显示和保存可视化图像

    参数：
    input_path: 原始数据文件路径(.npz/.npy)
    output_dir: 图像保存目录
    """
    import matplotlib.pyplot as plt

    # 确保输出目录存在
    os.makedirs(output_dir, exist_ok=True)

    try:
        # 加载数据
        rec = np.load(input_path)  # 支持.npy和.npz格式
        if isinstance(rec, np.lib.npyio.NpzFile):  # 处理.npz文件
            rec = rec['reconstructions']  # 根据实际键名调整

        # 验证数据形状
        assert rec.ndim == 4, "数据维度应为4维 (batch, H, W, C)"
        print(f"数据形状：{rec.shape} | 数据类型：{rec.dtype}")

        # 数值处理
        rec_normalized = np.clip(rec, 0.0, 1.0)

        # 创建子目录
        single_img_dir = os.path.join(output_dir, "stego_images/bits/64embed_images/32") #"512stego_images")
        os.makedirs(single_img_dir, exist_ok=True)

        # 显示并保存每个图像
#        plt.figure(figsize=(15, 10))
#        for i in range(min(rec_normalized.shape[0], 15)):  # 最多显示9张
#            img = rec_normalized[i]

#            # 显示图像
#            plt.subplot(3, 3, i + 1)
#            plt.imshow(img)
#            plt.axis('off')
#            plt.title(f'Image {i}')

            # 保存图像
#            img_uint8 = (img * 255).astype(np.uint8)
#            Image.fromarray(img_uint8).save(
#                os.path.join(single_img_dir,f"512clean_image_{i:03d}.png")) #f"512stego_image_{i:03d}.png"))

        # 显示并保存第10到第20张图像（索引从9到19）
        plt.figure(figsize=(15, 10))
        for i in range(9, min(rec_normalized.shape[0], 20)):  # 从第9个开始，最多显示到第19个
            img = rec_normalized[i]

            plt.subplot(3, 4, (i - 9) + 1)  # 使用 3 行 4 列 的子图布局显示 10~20 张图像
            plt.imshow(img)
            plt.axis('off')
            plt.title(f'Image {i}')

            # 保存图像
            img_uint8 = (img * 255).astype(np.uint8)
            Image.fromarray(img_uint8).save(
                os.path.join(single_img_dir, f"64embed_image_{i:03d}.png"))

        plt.tight_layout()
        plt.suptitle("Reconstructed Images", y=1.02)
        plt.show()

    except Exception as e:
        print(f"处理失败：{str(e)}")


def runsave(empath):
    save_dir = "generated_images_files/embed/bits"
    os.makedirs(save_dir, exist_ok=True)

    # 从文件路径提取 mod_dim
    import re
    match = re.search(r'celeba_modulations_(\d+)_latents_32bits\.npz', os.path.basename(empath))
    if not match:
        raise ValueError("文件名格式不正确，应为: celeba_modulations_64_latents_32bits.npz")
    mod_dim = int(match.group(1))
    print(f"自动检测到 mod_dim = {mod_dim}")

    """# Load pretrained weights"""
    os.environ['MOD_DIM'] = str(mod_dim)
    params_path = f'celeba_params_{mod_dim}_latents.npz'

    try:
        with open(params_path, 'rb') as f:
            ckpt = dill.load(f)
    except FileNotFoundError:
        raise FileNotFoundError(f"预训练参数文件 {params_path} 不存在，请确保已下载")

    params = ckpt['params']
    config = ckpt['config']
    assert config['model']['type'] == 'latent_modulated_siren'

    # 其余代码保持不变...
    model_config = config['model'].copy()
    model_config.pop('type', None)
    model_config.pop('l2_weight', None)
    model_config.pop('noise_std', None)

    def model_net(coords):
        hk_model = function_reps.LatentModulatedSiren(
            out_channels=config['dataset']['num_channels'], **model_config)
        return hk_model(coords)

    model = hk.without_apply_rng(hk.transform(model_net))

    # 原有代码继续...
    weights, init_modulation = function_reps.partition_params(params)
    init_modulation, concat_idx, tree_def = pytree_conversions.pytree_to_array(init_modulation)

    def render_image(modulation, coords):
        modulation_tree = pytree_conversions.array_to_pytree(
            modulation, concat_idx, tree_def)
        modulated_params = function_reps.merge_params(weights, modulation_tree)
        return model.apply(modulated_params, coords)

    render_image = jax.jit(jax.vmap(render_image))

    """# Load modulation dataset"""
    with open(empath, 'rb') as f:
        data = dill.load(f)
        train_dict = data['train']

    bs = 20
    train_mods = train_dict['modulations'][:bs]
    print("加载的调制参数形状:", train_mods.shape)
    assert train_mods.shape == (bs, mod_dim), f"形状不匹配: 期望{(bs, mod_dim)}, 实际{train_mods.shape}"

    """# Reconstruct and save"""
    coords = function_reps.get_coordinate_grid(config['dataset']['resolution'])
    coords = jnp.stack([coords for _ in range(bs)])
    rec = render_image(train_mods, coords)

    # 保存结果
    output_path = os.path.join(save_dir, f"{mod_dim}raw_reconstructions_embed32bits.npy")
    np.save(output_path, np.array(rec))
    print(f"重建结果已保存至: {os.path.abspath(output_path)}")
    raw_data_path = f"./generated_images_files/embed/bits/{mod_dim}raw_reconstructions_embed32bits.npy"  # 原始数据路径
    save_directory = "./individual_images"  # 新保存路径
    visualize_and_save_raw_data(
        input_path=raw_data_path,
        output_dir=save_directory
    )

if __name__ == "__main__":
    # 输入参数设置
    path = "celeba_modulations_64_latents_clean.npz"
    runsave("save/embed/bits/64/celeba_modulations_64_latents_32bits.npz")

# def runsave(empath):
#     save_dir = "generated_images"
#
#     # 创建目录（如果不存在）
#     os.makedirs(save_dir, exist_ok=True)
#
#     """# Load pretrained weights"""
#
#     # Load params of LatentModulatedSiren model
#     mod_dim = 256  # choose one of 64, 128, 256, 512, 1024
#     # Download pretrained weights
#     os.environ['MOD_DIM'] = str(mod_dim)
#     # Load pretrained weights
#     path = f'celeba_params_{mod_dim}_latents.npz'
#     # path = path
#     with open(path, 'rb') as f:
#         ckpt = dill.load(f)
#     params = ckpt['params']
#     config = ckpt['config']
#     assert config['model']['type'] == 'latent_modulated_siren'
#     print(f'Loaded params for model with {mod_dim} latent dimensions.')
#     # Create haiku transformed model that runs the forward pass.
#     # Only keep configs needed for model construction from model config
#     # `None` below ensures no error is given when already removed
#     model_config = config['model'].copy()
#     model_config.pop('type', None)
#     model_config.pop('l2_weight', None)
#     model_config.pop('noise_std', None)
#
#     def model_net(coords):
#         hk_model = function_reps.LatentModulatedSiren(
#             out_channels=config['dataset']['num_channels'], **model_config)
#         return hk_model(coords)
#
#     model = hk.without_apply_rng(hk.transform(model_net))
#
#     # Define function that renders image from a single modulation
#     weights, init_modulation = function_reps.partition_params(params)
#     init_modulation, concat_idx, tree_def = pytree_conversions.pytree_to_array(
#         init_modulation)
#
#     def render_image(modulation, coords):
#         modulation_tree = pytree_conversions.array_to_pytree(
#             modulation, concat_idx, tree_def)
#         modulated_params = function_reps.merge_params(weights, modulation_tree)
#         return model.apply(modulated_params, coords)
#
#     # Use jit and vmap to render faster on a batch of modulations
#     render_image = jax.jit(jax.vmap(render_image))
#
#     """# Load modulation dataset and grab a batch of modulations"""
#
#     # Download and load a batch of modulations.
#     # Ensure that the modulation dataset has been downloaded to the correct dir.
#     path = f'{empath}'
#     with open(path, 'rb') as f:
#         data = dill.load(f)
#         train_dict = data['train']
#         # test_dict = data['test']
#
#     bs = 1
#     # test_mods = test_dict['modulation'][:bs]
#     # assert test_mods.shape == (bs, mod_dim)
#
#     train_mods = train_dict['modulations'][:bs]
#     print("加载的调制参数形状:", train_mods.shape)  # 调试输出
#     assert train_mods.shape == (bs, mod_dim)
#     # 修改后（直接取第一个样本）
#     # test_mods = test_dict['modulation'][:bs].reshape(bs, -1)
#     train_dict = train_dict['modulations'][:bs].reshape(bs, -1)
#
#     assert train_mods.shape == (bs, mod_dim), f"形状不匹配: 期望{(bs, mod_dim)}, 实际{train_mods.shape}"
#
#     """# Reconstruct batch of modulations and visualize reconstructions"""
#
#     # Create coords and tile for vmapping
#     coords = function_reps.get_coordinate_grid(config['dataset']['resolution'])
#     coords = jnp.stack([coords for _ in range(bs)])  # (bs, H, W, 2)
#     # Reconstruct test_mods
#     rec = render_image(train_mods, coords)  # (bs, H, W, 3)
#
#     print("rec数据类型:", rec.dtype)
#     print("rec最小值:", jnp.min(rec))
#     print("rec最大值:", jnp.max(rec))
#
#     # 保存原始 rec 数据（包括浮点数值）
#     # raw_data_path = os.path.join(save_dir, "512raw_reconstructions_Jax.npy")
#     # jnp.save(raw_data_path,rec)  # JAX 格式
#
#     # 或转换为 NumPy 数组保存
#     raw_data_path = os.path.join(save_dir, "128raw_reconstructions_embed.npy")  # 组合路径
#     np.save(raw_data_path, np.array(rec))
#
#     print(f"所有文件已保存至：{os.path.abspath(save_dir)}")
#
#     raw_data_path = os.path.join(save_dir, path)
#     save_directory = "./embeded_images"  # 新保存路径
#
#     # === 新增消息提取模块 ===
#     def extract_message(img_array: np.ndarray) -> jnp.ndarray:
#         """从图像数组提取消息"""
#         # 转换为JAX数组并展平
#         img_jax = jnp.array(img_array, dtype=jnp.float32)
#         img_flat = img_jax.reshape(-1)  # (64*64*3,)
#
#         # 使用embed模块的提取器
#         # extracted_msg = extractor_fn.apply(fixed_extractor_params, img_array.reshape(-1))
#
#         extracted_msg = embed_fnn.extractor_fn.apply(embed_fnn.fixed_extractor_params, img_array.reshape(-1))
#         # 二值化处理
#         return jnp.where(extracted_msg > 0, 1, 0)  # 转换为0/1比特
#
#     def calculate_bit_accuracy(extracted: jnp.ndarray) -> float:
#         """计算比特准确率"""
#         # 加载原始消息并转换格式
#         original_bits = (embed_fnn.original_msg > 0).astype(jnp.int32)[:100]
#         # 截取前100位
#         extracted_bits = extracted[:100]
#         # 计算准确率
#         return jnp.mean(extracted_bits == original_bits).item()
#
#     # === 新增消息提取流程 ===
#     print("\n=== 开始消息提取 ===")
#
#     # 加载生成的图像数据
#     rec_array = np.load(raw_data_path)  # 形状 (1, H, W, 3)
#     test_image = rec_array[0]  # 取第一个样本 (64, 64, 3)
#     # 执行消息提取
#     extracted_bits = extract_message(test_image)
#
#     # 计算准确率
#     # def calculate_bit_accuracy(extracted: jnp.ndarray) -> float:
#     #     original_bits = (embed_fnn.original_msg > 0).astype(jnp.int32)[:100]
#     #     extracted_bits = extracted[:100]
#     #     return jnp.mean(extracted_bits == original_bits).item()
#
#     def calculate_accuracy(extracted_msg):
#         """计算提取消息的比特准确率"""
#         predicted_bits = jnp.sign(extracted_msg)  # 将连续值转换为二进制比特（-1/1）
#         # 计算准确率
#         accuracy = jnp.mean(jnp.equal(predicted_bits, embed_fnn.original_msg))
#         return accuracy
#
#     accuracy = calculate_bit_accuracy(extracted_bits)
#
#     # 保存并显示结果
#     print(f"比特准确率: {accuracy:.2%}")
#     np.save(os.path.join(save_dir, "extracted_message.npy"), extracted_bits)
#
#     # 对比前20位
#     print("\n[前20位对比]")
#     print("原始:", (embed_fnn.original_msg[:20] > 0).astype(int).tolist())
#     print("提取:", extracted_bits[:20].tolist())
#
#     raw_data_path = f"./generated_images/{path}"  # 原始数据路径
#     save_directory = "./individual_images"  # 新保存路径
#
#     # 执行可视化保存
#     # visualize_and_save_raw_data(
#     #     input_path=raw_data_path,
#     #     output_dir=save_directory
#     # )

